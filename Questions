Throughout this project, we acted as investigators to uphold the system of accountability created by the San Francisco
lawmakers: listers must register with the city’s planning office and put the business license’s number on Airbnb’s website,
Airbnb must display some effort in validating these policy numbers, and third parties can register a complaint of illegal
short-term rentals with the city planning office. We used web-scraping to do the latter using several hours of our personal
time. Imagine you’re a software developer at either the San Francisco Planning Office (SFPO) or Airbnb.com. Describe a
different system that verifies that the business license is valid for short term rentals in San Francisco and list at least
two arguments you might hear at your organization (either SFPO or Airbnb.com) against adopting your system.

	From the perspective of Airbnb.com, a better system could be implemented if Airbnb engineers had application programming 
	interface access to the databases of valid license numbers. This would allow Airbnb to validate the numbers for San 
	Francisco listings. Two arguments that could arise in opposition to this suggestion would be that it’s the government’s 
	responsibility to catch illegal listing activity, and that having access to extensive databases is intrusive to lister 
	privacy.

The database we’ve created through web-scraping is a great data source of information for data scientists in order to answer 
and explore research questions. Skim through the Housing Insecurity in the US Wikipedia page and describe at least one 
research question that you could answer or explore using this data if you were a data scientist working with a housing 
activist organization to fight against housing insecurity.

	One research question we could explore with this data is the correlation between housing/rent pricing is correlated with 
	Airbnb listing availability and pricing. With rising living costs in the US, specifically in cities like San Francisco, we 
	might predict that prices on Airbnb would parallel housing prices and rising rent. In addition, we could also look at the 
	number and types of availability on Airbnb. Perhaps, through this question, we might see a rising number of listings, 
	including illegal listings, as a result of higher housing insecurities.

As discussed in the introduction, the legality of web scraping is still uncertain in the US. Skim through the Legal Issues 
section of Web Scraping in the US on Wikipedia and this article about the legal issues with the Computer Fraud and Abuse Act, 
and describe at least one factor you believe is important to consider when discussing the legality of web scraping and why. 

	The legality of web scraping is an uncertain issue that has had conflicting discussion and rulings. Lawsuits regarding web 
	scraping have been heard for years now, with some shutting it down for its ties with bot spamming and copyright, as well 
	as other cases in which web scraping is an issue that holds websites responsible for security and user data privacy. That 
	said, some important factors to consider when discussing the legality of web scraping are the boundaries between data 
	hijacking and web scraping. Web scraping itself is legal, but at what point is web scraping too invasive? This also leads 
	us back to the questions of who is responsible when web scraping has gone too far. Is it the responsibility of data 
	seekers to web scrape ethically, or is it the job of websites and online platforms to keep their and their users’ data 
	private, or is it both? Privacy and accountability are two important factors when approaching the gray area of web 
	scraping.

Scraping public data does not always lead to positive results for society. While web scraping is important for accountability 
and open access of information, we must also consider issues of privacy as well. Many argue that using someone’s personal data 
without their consent (even if publicly provided) is unethical. Web scraping requires thoughtful intervention, what are two or 
more guidelines that must we consider when deciding to use or not to use public data?

	One guideline that we must consider when deciding to use or not to use public data is the extent to which the intentions 
	of our web scraping are good or bad. If our intentions are to solely benefit ourselves, then we shouldn’t utilize web 
	scraping. An example of this includes stealing private information from websites for financial gain. Because web scraping 
	is already on the borderline of being a privacy issue, it should only be used for the greater good of society (ex: 
	exposing criminal activity, discrimination, etc). Another guideline that affects our decision on accessing public 
	information is the type of information inside the data. If the data is filled with a bunch of private information on 
	random individuals, it would be a violation of privacy to scrape this data. However, if the type of information is housing 
	data or company financial information, scraping it doesn’t necessarily invade any individual's privacy. Therefore, data 
	should only be scraped if it is broad enough to avoid violating privacy on a person to person level. Data that relates to 
	corporations or large entities should be allowed to be subject to web scraping.